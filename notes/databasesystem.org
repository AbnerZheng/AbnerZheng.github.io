
* Charpter8  Overview of storage and indexing
  在DBMS中，数据被抽象为记录的集合，抽象为一个包含一页或更多的页。选择构建一个好的索引集合是一个DBA提高性能的最强大工具。

** 外部存储中的数据
数据库中的数据一般持久化在外部存储中，诸如硬盘。读取的最小单位是页（page）, 一般设为4KB或8KB。IO操作是一个数据库的瓶颈，数据库系统会重点优化。
CPU通过一个称为缓存管理器(buffer manager)的软件来操作磁盘上的数据。当文件访问函数需要一些数据时，传给缓存管理器页的rid， 如果缓存管理器中没有该数据，则将磁盘中对应的数据读入缓存管理器。
** 文件组织和索引
   在DBMS中，记录文件是一个重要的抽象，被代码中的文件和获取方法所实现。它还得支持scan，允许每次访问一个文件中的一个记录。
   索引是一种通过组织硬盘中数据记录优化数种取回操作的数据结构。一个索引能够允许我们高效得取得满足在该索引构建的域搜索条件的数据。同时我们也可以在其他搜索词上构建额外的所以，帮助提高查找速度。这里有三种方法来存储一个索引记录：
1. 实际的记录数据
2. (k, rid),其中rid是与索引k对应的数据记录的记录id
3. <k, rid-list>, 其中rid-list是索引k对应的所有记录的rid组成的list

方法1能够用来替代排序或未排序文件方法。在构建索引的时候，方法1最多只能使用一次，以避免过多的重排序。方法2和方法3都是使用rid指针指向记录，方法三的空间利用效率更高，但是必须维护一个length字段来记录rid-list的个数。
** 聚簇索引
   当记录的文件存储顺序和索引数据条目的顺序相同或相近时，我们称之为聚簇索引，否则就是非聚簇索引。当使用上节所讲的方法1构建的索引是聚簇索引。而方法2和3仅当数据记录在文件中按该索引排序的时候，才是聚簇索引。
在现实中，在数据更新时，维护有序的操作代价太高昂以至于文件很少保持有序，所以在现实中，一般使用方法1构建的索引是聚簇索引，而其他两种是非聚簇索引。

在查找一个范围时，是否为聚簇索引对io操作代价有巨大的影响。如果是聚簇索引，那么符合条件的记录被连续地存储在文件上，这样就只需访问有限的几个页即可。然而当不是聚簇索引时，几乎每条记录都要引起一个page的读写。
** 主、次索引
   索引建立的字段中包含主键即为主索引，其他的都为次索引。（在这里需要注意的是，主索引和次索引可能会和前文的方法1和方法2、3建立的索引术语冲突，因为这些术语并没有标准）
** 索引数据结构
   索引的数据结构一般包括hash和类树结构。

*** 基于hash的索引
基于hash的索引是构建在某一搜索键值上的，可以想象，当建立在非uniqe key上时，索引冲突会发生，此时相同键值的数据以链表的形式连接。通过哈希索引，我们可以在一或两个磁盘io就可访问到该hash对应的主页(primary page)。
#+CAPTION: hash索引例子
#+ATTR_HTML: :width 400
[[file:///Users/abnerzheng/Github/AbnerZheng.github.io/images/post/hash_index_example.jpg]]

在上图中，左边即为方法1,每个hash直接指向一个数据记录，右边为方法2。在右边，每个hash指向一条由(sal, rid)组成的数据条目。

*** 基于树的索引


** 文件组织形式的比较

*** 代价模型

本书采用了一个简单的代价模型来衡量数据库操作。其要素如下：

| 符号 | 含义                         | 常见值          |
|------+------------------------------+-----------------|
| B    | page总数                     |                 |
| R    | 每页的记录数                 |                 |
| D    | 读写磁盘的平均时间           | 15毫秒(主导)    |
| C    | 处理记录的平均时间           |                 |
| H    | hash函数所用时间             | 100 纳秒        |
| F    | fan-out,树结构的平均孩子个数 | 在B+树中，>>100 |

这里认为处理记录的平均时间(C)为一个常数。该模型需要注意一下几个点:
1. 在实际系统中，需要考虑cpu、网络传输大小等因素
2. 在实际中，IO更复杂，比如，操作系统允许我们以块模式读取磁盘，此时，他的时间即为：寻找第一个page的寻找时间+所有page的传输时间，因此解约了很多的寻址空间。

*** Heap Files

**** Scan(遍历): 代价为B(RC+D)， 即对每页，需要时间D，之后处理R条记录，每个需要C时间，一共B页。

**** 等值查找: 当搜索是在候选键上搜索的话，代价为B/2*(RC+D)，平均来说，在随机情况中，找到的期望值为0.5。而当不是的时候，代价为B(RC+D), 完全遍历。

**** 范围查找: 完全遍历，代价为B(RC+D)

**** 插入:  可以假设插入都是在文件末尾，所以为2D+C

**** 删除: 先找到然后删除， 找到之后的删除有可能需要压缩，加入不需要压缩的话，则需要C+D + 搜索。

*** Sorted Files


*** 索引和性能调整
    这个讨论依赖于数据库查询和并发控制的理解。
* Charpter9
** Page format (页格式)
通过抽象，DBMS上层认为数据是一系列的记录。但是在底层中，可以这么理解： 每一页都由很多槽组成，而每个槽(slot)包含一条记录。记录由(page_id, slot_number)来唯一辨识，即rid(虽然也可以使用一个uuid指向这个元祖，但是考虑到维护成本，一般采用的都是直接使用该元组作为rid)
*** 固定长度的记录
如果记录的长度是固定的话，那么每个记录槽都是固定长度的，这样就能够连续地放在一个页中。这样，操作的难点就在于如何跟踪这些空槽和如何在一页中遍历所有的记录以及如何处理记录的删除。有如下几种算法：
算法1: 将N条record记录连续存放在page中，当需要删除record_{i}时，删除它，然后将record_{N-1}移到record_{i}所在的slot上。这样，所有的空闲slot都在最后面，此时只要维护一个指针，就可以实现O(1)的插入效率。然而当有外部指向的记录被删除时，该方式就不能运作。

算法2: 通过在页头(page header)中加入一个bit vector,一对一对应record slot是否空闲，来实现。在插入时，需要遍历该vector以找到第一个为0的bit。

一般来说，页头中也会包含一些诸如下一页等信息。
*** 变长的记录
因为每个记录是变长的，所以我们再也不能将每一页分为固定个数的slot。这里有两个问题：
1. 插入: 如何分配合理的空间
2. 删除: 保证删除得到空间在以后能够得以利用。
这里面，在页中移动记录成为至关重要的解决基石。
#+CAPTION: 变长记录数据组织图
#+ATTR_HTML: :width 100
[[file:///Users/abnerzheng/Github/AbnerZheng.github.io/images/post/varianceSlot.jpg]]:

其数据结构可以组织为一下:
#+BEGIN_SRC C
  struct slot_directory{
      int* slot;
      int length; // The length of slot
  };
  struct page_header{
      int* start_of_free_space;
      int free_space_length; //空闲空间的长度
      int N; // Number of entries in slot directory
      struct slot_directory* slot_ds; //slot direcotry vector
  };
#+END_SRC

在删除操作中，直接将page_header中的slot ds对应的指针置为null, 无其余操作。在插入record_{i}时:如果free_space_length > record_{i}.length,则插入。否则，重组该页。

#+BEGIN_SRC python
  def insert(page_header, record_i):
      if record_i.length <= free_space_length:
          page_header.N+=1
          page_header.slot_ds.push(record_i)
          page_header.free_space_length -= record_i.length
      else:
          reorganize(page_header)
          if page_header.length < record_i.length:
              page_header = page_header.next
              insert(page_header, record_i)
          else:
              insert(page_header, record_i)
#+END_SRC

*** TODO 加入Record format
